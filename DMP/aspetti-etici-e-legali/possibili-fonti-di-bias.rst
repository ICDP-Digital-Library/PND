7.6.3. Possibili fonti di *bias* ⓘ
==================================

Nella produzione, modellazione ed elaborazione dei dati è possibile che
vengano introdotti *bias*, ovvero distorsioni che rendono i dati non
rappresentativi della realtà, in particolare per quanto riguarda la
rappresentazione delle minoranze e delle comunità marginalizzate. È
opportuno che nella gestione di un progetto siano individuate tutte le
possibili fonti di *bias*, e che si prevedano meccanismi per correggerli
(oppure, ove non fosse possibile, contestualizzarli).

La pubblicazione di dataset contenenti *bias* corre infatti il rischio
di perpetuare le diseguaglianze sociali, ad esempio quelle di
genere [1]_, etnia, lingua, religione, orientamento sessuale. Nella
rappresentazione di dati storici, è inoltre particolarmente frequente
che esistano *bias* “per omissione”, ovvero che nel dataset siano state
privilegiate talune categorie sociali rispetto ad altre al punto di
rendere queste ultime invisibili [2]_.

Qualora i dati fossero stati elaborati tramite metodi di intelligenza
artificiale (es. apprendimento automatico di conoscenza da testi o
immagini), occorre considerare i limiti degli attuali sistemi di
*machine learning* e valutare attentamente i possibili *bias* che ne
derivano [3]_.

In questo paragrafo vanno descritti:

-  I possibili *bias* derivanti dalla produzione e raccolta dei dati

-  I possibili *bias* derivanti dal riuso di dati esistenti

-  I possibili *bias* derivanti dai modelli utilizzati per rappresentare
   i dati

-  I possibili *bias* derivanti dall’uso di sistemi di intelligenza
   artificiale

-  Eventuali ulteriori tipologie di *bias* individuabili nel progetto

-  Per ogni tipologia di cui sopra, le modalità con cui si prevede di
   farvi fronte

.. [1]
    D’Ignazio, C. and Klein, L. F. (2020). Data Feminism. <Strong> Ideas
   Series. MIT Press.

.. [2]
    Ortolja-Baird, A. & Nyhan, J. (2021). "Encoding the haunting of an
   object catalogue: on the potential of digital technologies to
   perpetuate or subvert the silence and bias of the early-modern
   archive." \ \ *Digital Scholarship in the Humanities*.

.. [3]
    Bender, Emily M., et al. "On the Dangers of Stochastic Parrots: Can
   Language Models Be Too Big?" \ \ *Proceedings of the 2021 ACM
   Conference on Fairness, Accountability, and Transparency*. 2021.
